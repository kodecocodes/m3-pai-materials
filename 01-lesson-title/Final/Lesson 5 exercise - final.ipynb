{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35754509",
   "metadata": {},
   "source": [
    "# Lesson 5 exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d5ac4",
   "metadata": {},
   "source": [
    "## Install the OpenAI Python package on your system\n",
    "\n",
    "Like any other Python package, you install the OpenAI package using `pip`, which is short for “Package Installer for Python.” Run the cell below to install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0d1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.37.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c70c1",
   "metadata": {},
   "source": [
    "(If the above doesn’t work, try `pip3 install openai` instead.)\n",
    "\n",
    "In a Jupyter Notebook code cell, any line that begins with the `!` character is executed as a shell command — that is, it’s as if you typed it on the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e4347",
   "metadata": {},
   "source": [
    "## Create an OpenAI client object\n",
    "\n",
    "To make use of OpenAI’s APIs, you need to create an OpenAI ___client___ object. You’ll use it throughout the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d709a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# When called without arguments, OpenAI will try to get\n",
    "# the API key from the OPENAI_API_KEY environment variable.\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2af18",
   "metadata": {},
   "source": [
    "\n",
    "In the ChatGPT API, a ___completion___ refers to the response generated by the model based on the input it receives. When you send a prompt to the API, the model processes this input and produces a text output, which is the \"completion.\" This output is intended to complete the prompt in a coherent and contextually relevant manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fac423b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m current_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAsk OpenAI\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_model\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m model a question: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mcurrent_model,\n\u001b[1;32m      6\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     ],\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(completion)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "current_model = \"gpt-4o-mini\"\n",
    "prompt = input(f\"Ask OpenAI's {current_model} model a question: \")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=current_model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ede70",
   "metadata": {},
   "source": [
    "The `input()` function collects keyboard input from the user. It takes one argument, which it uses as a prompt (in this case, it’s `Say something: `), and it returns a string containing whatever the user entered. The code above stores whatever the user entered into a variable named prompt.\n",
    "\n",
    "The next line communicates with OpenAI using the `client.chat.completions.create()` method of the `ChatCompletion` class of the `openai` module. The `client.chat.completions.create()` method creates a _ChatCompletion_, which is an artificial intelligence model that takes a number of messages as input and generates a result as output. It’s called a “completion” because you feed it the first part of a conversation, and the result it provides completes the conversation.\n",
    "\n",
    "The code above provides the two parameters that all calls to the `client.chat.completions.create()` method must provide:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><strong>Parameter</strong></td>\n",
    "        <td style=\"text-align:left;\"><strong>Description</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>model</code></td>\n",
    "        <td>\n",
    "            <p>The name of the AI model that should be used to create the completion.</p>\n",
    "            <p>In the code above and in all the code in this exercise, we’re using the _GPT-4o mini_ model, \n",
    "               a “lite” version of their flagship GPT-4o model. It’s useful enough for most purposes, and is \n",
    "               quite inexpensive — generally a fraction of a cent for each completion.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>messages</code></td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            <p>A list of input messages to be provided to the completion.</p>\n",
    "            <p>Each message is a dictionary containing the following keys:</p>\n",
    "            <ul>\n",
    "                <li>\n",
    "                    <code>“role”</code>: This specifies who the message is from. The message can be from one of three entities:\n",
    "                    <ol>\n",
    "                        <li><code>“user”</code>: Messages with the “user” role contain questions or requests from the user or entity that wants a response from the AI model.</li>\n",
    "                        <li><code>“system”</code>: Messages with the “system” role usually contain some high-level instructions to guide the behavior of the AI. By default, the AI acts as if it was given a “system” message of “You are a helpful assistant.”</li>\n",
    "                        <li><code>“assistant”</code>: This role represents the responses given by the AI model.</li>\n",
    "                    </ol>\n",
    "                </li>\n",
    "                <br />\n",
    "                <li><code>“content”</code>: As its name implies, this contains the content of the message.</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "The code in the cell provides only one message, where the role is “user” and the message is the contents of the prompt variable, which contains whatever the user entered into the text input field.\n",
    "The thing in the `ChatCompletion` object that we’re most interested in is the actual response or response_s_, which are contained in `ChatCompletion`’s `choices` property, which is an array.\n",
    "\n",
    "Each element of `choices` has a `message` property, which represents a message from the model. The text of the message is contained in `message`’s `content` property.\n",
    "\n",
    "Let’s extract the actual message content!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad136743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The world's tallest building is the Burj Khalifa in Dubai, United Arab Emirates. It stands at a height of 828 meters (2,717 feet).\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716df1f",
   "metadata": {},
   "source": [
    "## Create a chat completion function\n",
    "\n",
    "Let’s take the code we’ve written so far and turn it into a function that takes a prompt as its input and outputs a completion as its result. It will simply be some of the code you’ve written so far, but put inside a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876941d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_completion(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e697f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Earth has a mass of approximately 5.972×10^24 kilograms, which is equivalent to about 13.2×10^24 pounds.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_completion(\"How much does the Earth weigh?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a91951",
   "metadata": {},
   "source": [
    "## Turn up the temperature on the chat completion function\n",
    "\n",
    "OpenAI’s chat completions have useful optional parameters. One of them is `temperature`, which specifies the amount of randomness in the answers it generates. \n",
    "\n",
    "Temperature is a value typically between 0 and 1, where lower values are supposed to produce completions that are more focused and deterministic, while higher values are expected to be more random and creative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf363f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_completion(prompt, temp=0.7):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a75cd",
   "metadata": {},
   "source": [
    "This redefines the `create_completion()` function and adds a new parameter, `temp`.\n",
    "\n",
    "I’m using Python’s “default argument” feature — if you don’t assign a value to `temp`, it sets it the default value of `0.7`. That should make the completions fairly creative, but not too wild.\n",
    "\n",
    "Try the following. There’s no value for the `temp` parameter, so `create_completion()` will use the default value of `0.7`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10accf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Captain Blackbeard is a notorious pirate known for his fearsome reputation and ruthless tactics on the high seas. With a long black beard and a menacing glare, he strikes fear into the hearts of all who cross his path. Despite his hardened exterior, Captain Blackbeard is a cunning strategist and a master of the sword, always one step ahead of his enemies. He is driven by a thirst for power and treasure, willing to do whatever it takes to achieve his goals.\n",
      "\n",
      "2. Anne Bonny is a fierce and independent pirate who defies the conventions of her time. With fiery red hair and a sharp wit, she is a force to be reckoned with on the open waters. Anne is a skilled fighter and a natural leader, commanding respect from her crew and striking fear into her adversaries. Despite her tough exterior, she also has a compassionate side, standing up for those who cannot defend themselves and fighting for justice in a world plagued by greed and corruption. Anne's loyalty to her crew and her unwavering determination make her a formidable ally in the dangerous world of piracy.\n"
     ]
    }
   ],
   "source": [
    "print(create_completion(\"I need two one-paragraph descriptions of characters for a young adult adventure novel set in the age of pirates\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219239e",
   "metadata": {},
   "source": [
    "It turns out that OpenAI’s `temperature` parameter accepts values higher than 1 — they can go as high as 2. The results take a longer time to produce, and they get sillier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1687a003",
   "metadata": {},
   "source": [
    "## Add system guidance to the chat completion function\n",
    "\n",
    "Your application can add additional guidance for OpenAI’s completion by adding a message with a “system” role. Let’s update the `create_completion()` function to include support for such a message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bcff064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_completion(prompt, temp=0.7, system_prompt=\"\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b1584a",
   "metadata": {},
   "source": [
    "This provides an additional message to OpenAI. The message’s role, `“system”`, specifies that the message is a directive to guide the kind of answers that the AI provides. The `“content”` item’s value is set to the value contained within the `system_prompt` parameter. If you don’t provide a value for `system_prompt`, this value is an empty string, which is the same as not providing any kind of system guidance at all.\n",
    "\n",
    "Let’s test this new `create_completion()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddcac16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, the first law of thermodynamics, huh? You're really diving deep there! Alright, let me break it down for you like I would a sweet deal on a used car. \n",
      "\n",
      "So, the first law says energy can't just pop in and out of existence, right? It's like when you drive off the lot in one of my fine pre-owned vehicles – you can't just expect gas to magically fill the tank without putting some cash in. Energy has to come from somewhere, and it can’t just disappear into thin air. \n",
      "\n",
      "Basically, it’s all about conservation – energy in a closed system is constant. You can transform it from one form to another, like turning that sweet horsepower into mileage, but you can't create or destroy it. \n",
      "\n",
      "So, think of it this way: you put in some energy, you get some energy out, and it’s all about making sure you’re not losing anything along the way. Just like how I make sure you don’t lose any of your hard-earned cash when you drive off with one of my top-notch deals! You follow me? Now, how about I show you a nice little sedan that runs like a dream?\n"
     ]
    }
   ],
   "source": [
    "print(create_completion(\"Explain the first law of thermodynamics\", system_prompt=\"Answer as if you were a shady used car dealer.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf0c5b",
   "metadata": {},
   "source": [
    "## Getting information from other APIs\n",
    "\n",
    "Suppose we want to create an app that gets the weather for a given city and writes a poem about it. We can do that by combining OpenAI and other APIs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e49152",
   "metadata": {},
   "source": [
    "### Get a location’s latitude and longitude from a place name or address\n",
    "\n",
    "The location APIs we’ll be using in this app will require the latitude and longitude of the place in question, so we need to create a function to convert place names to coordinates. We can do this by using a geocoding API. \n",
    "\n",
    "_Geocoding_ is the process of converting a place name or address into coordinates — more specifically latitude and longitude. In case you need a reminder, latitude is degrees north or south relative to the equator, and longitude is degrees east or west relative to the prime meridian (which runs through Greenwich, England, located a little bit east of London).\n",
    "\n",
    "![Chart explaining latitude (horizontal lines parallel to the equator) and longitude (vertical lines parallel to the prime meridian)](https://www.globalnerdy.com/wp-content/uploads/2023/10/latitude-vs-longitude.jpg)\n",
    "\n",
    "[GeoPy](https://geopy.readthedocs.io/en/stable/) is a Python module that makes it easy for a Python application to access several geocoding services, some of which are free, while others require money. We’ll use it to access the [Nominatim](https://nominatim.org/) geocoder, which uses [OpenStreetMap](https://www.openstreetmap.org/) data and doesn’t require you to sign up for an API key or provide a credit card number.\n",
    "\n",
    "First, you’ll need to install GeoPy on your system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc12865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from geopy) (2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94191119",
   "metadata": {},
   "source": [
    "Here’s a function that takes a place name or address and uses Nominatim to convert it into latitude and longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3aca3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def location_name_to_latlong(location_name):\n",
    "    geolocator = Nominatim(user_agent=\"Computer Coach online AI bootcamp\")\n",
    "    location = geolocator.geocode(location_name)\n",
    "    return (location.latitude, location.longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11365b",
   "metadata": {},
   "source": [
    "The `user_agent` parameter should contain the name of the app using the Nominatim service.\n",
    "\n",
    "Try it out by using it to get the latitude and longitude of Tampa International Airport:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97d2e629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27.9791649, -82.5349276153517)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are Tampa International Airport’s coordinates?\n",
    "location_name_to_latlong(\"Tampa International Airport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06047b8a",
   "metadata": {},
   "source": [
    "### Get the time at the location\n",
    "\n",
    "The app draws a picture of the location, so it would be helpful if we could provide it with the current time at the location so that it “knows” whether to draw a daytime scene, a nighttime scene, or something in between.\n",
    "\n",
    "To do this, we’ll use the `timezonefinder` package, which takes a latitude/longitude coordinate pair and returns the time zone for those coordinates. It does its job entirely offline; it doesn’t make any calls to external APIs.\n",
    "\n",
    "First, install the `timezonefinder` package..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0861ef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timezonefinder in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (6.5.2)\n",
      "Requirement already satisfied: cffi<2,>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from timezonefinder) (1.16.0)\n",
      "Requirement already satisfied: h3<4,>=3.7.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from timezonefinder) (3.7.7)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from timezonefinder) (2.0.1)\n",
      "Requirement already satisfied: setuptools>=65.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from timezonefinder) (70.3.0)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cffi<2,>=1.15.1->timezonefinder) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install timezonefinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34898c92",
   "metadata": {},
   "source": [
    "...and here’s a function that converts coordinates to a time zone name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc8c2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timezonefinder import TimezoneFinder\n",
    "\n",
    "def get_timezone_from_latlong(latitude_longitude_tuple):\n",
    "    latitude, longitude = latitude_longitude_tuple\n",
    "    tz_finder = TimezoneFinder()\n",
    "    return tz_finder.timezone_at(lat=latitude, lng=longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8decf3ac",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5f9921c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'America/New_York'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_timezone_from_latlong(location_name_to_latlong(\"Tampa, FL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b266578",
   "metadata": {},
   "source": [
    "Now that we know the time zone for the location, we need the time at that location. There are a number of ways to do this; I’ve chosen to use the [World Time API](https://worldtimeapi.org/).\n",
    "\n",
    "Here’s a function that takes a timezone name and returns the current date and time in that time zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9da8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def get_current_date_and_time_in_timezone(timezone_name):\n",
    "    url = f\"http://worldtimeapi.org/api/timezone/{timezone_name}\"\n",
    "    response = requests.get(url)\n",
    "    json = response.json()\n",
    "    raw_date_and_time = json[\"datetime\"]\n",
    "    date_and_time = datetime.strptime(raw_date_and_time, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    current_time = datetime.strftime(date_and_time, \"%-I:%M %p on %A, %B %-d\")\n",
    "    return current_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a9850",
   "metadata": {},
   "source": [
    "Once we have that function, we can write a function that takes a location name and returns the current date and time at that location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67f79b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_date_and_time_in_location(location_name):\n",
    "    return get_current_date_and_time_in_timezone(\n",
    "        get_timezone_from_latlong(location_name_to_latlong(location_name))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e10f05",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b31d1bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2:52 PM on Friday, August 2'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_date_and_time_in_location(\"San Francisco, CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a87b1",
   "metadata": {},
   "source": [
    "### Get the current weather\n",
    "\n",
    "There are a number of weather APIs out there. Let’s use the one from [Open-Meteo](https://open-meteo.com/) — _météo_ is French for _weather_ — which is free for non-commercial use and if you make fewer than 10,000 calls to it per day. It’s perfect for experimental applications or apps with relatively few users. It doesn’t require you to sign up for an API key, and you don’t have to provide a credit card number. You can just use it.\n",
    "\n",
    "You can find out more about the API in [Open-Meteo’s documentation](https://open-meteo.com/en/docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65a20424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# import json\n",
    "\n",
    "WEATHER_CODE_TABLE = {\n",
    "    0: \"clear sky\",\n",
    "    1: \"mainly clear\",\n",
    "    2: \"partly cloudy\",\n",
    "    3: \"overcast\",\n",
    "    45: \"fog\",\n",
    "    48: \"depositing rime fog\",\n",
    "    51: \"light drizzle\",\n",
    "    53: \"moderate drizzle\",\n",
    "    55: \"dense drizzle\",\n",
    "    56: \"light freezing drizzle\",\n",
    "    57: \"dense freezing drizzle\",\n",
    "    61: \"slight rain\",\n",
    "    63: \"moderate rain\",\n",
    "    65: \"heavy rain\",\n",
    "    66: \"light freezing rain\",\n",
    "    67: \"heavy freezing rain\",\n",
    "    71: \"slight snow\",\n",
    "    73: \"moderate snow\",\n",
    "    75: \"heavy snow\",\n",
    "    77: \"snow grains\",\n",
    "    80: \"light rain showers\",\n",
    "    81: \"moderate rain showers\",\n",
    "    82: \"violent rain showers\",\n",
    "    85: \"slight snow showers\",\n",
    "    86: \"heavy snow showers\",\n",
    "    95: \"thunderstorm\",\n",
    "    96: \"thunderstorm with slight hail\",\n",
    "    99: \"thunderstorm with heavy hail\",\n",
    "}\n",
    "\n",
    "def celsius_to_fahrenheit(degrees_celsius):\n",
    "    return (degrees_celsius * 1.8) + 32\n",
    "\n",
    "def get_current_weather(location_name):\n",
    "    latitude, longitude = location_name_to_latlong(location_name)\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,relativehumidity_2m,weathercode,cloudcover\"\n",
    "    response = requests.get(url)\n",
    "    json = response.json()\n",
    "    result = {\n",
    "        \"weather\": WEATHER_CODE_TABLE.get(json[\"current\"][\"weathercode\"], \"unknown\"),\n",
    "        \"cloud_cover\": json[\"current\"][\"cloudcover\"],\n",
    "        \"temperature\": celsius_to_fahrenheit(json[\"current\"][\"temperature_2m\"]),\n",
    "        \"humidity\": json[\"current\"][\"relativehumidity_2m\"],\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76717b5",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "Here’s what the `import`ed modules do:\n",
    "    \n",
    "* **`requests`**: Contains functions for sending HTTP requests.\n",
    "* **`json`**: Contains functions for encoding and decoding JSON data.\n",
    "\n",
    "The next part of the code defines a dictionary called `WMO_CODE_TABLE`,  which is used to convert Open-Meteo’s weather forecast numbers into meaningful phrases, such as converting “2” into something more comprehensible: “partly cloudy.”\n",
    "\n",
    "The final part of the code is the function itself — `get_current_weather()` — which takes a place name or address and returns a dictionary containing key elements of the forecast:\n",
    "\n",
    "* The weather, expressed as a weather code number\n",
    "* Cloud cover, expressed as a percentage\n",
    "* Temperature, in degrees C\n",
    "* Humidity, expressed as a percentage\n",
    "\n",
    "Open-Meteo’s API expects latitude and longitude, not a place name. That’s where the `location_name_to_latlong()` function we wrote earlier comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60520e0a",
   "metadata": {},
   "source": [
    "Try out the `get_current_weather()` function for Tampa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5462e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weather': 'overcast',\n",
       " 'cloud_cover': 94,\n",
       " 'temperature': 89.96000000000001,\n",
       " 'humidity': 87}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(\"Tampa, FL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be4a50c",
   "metadata": {},
   "source": [
    "### Create a weather poem prompt\n",
    "\n",
    "We now have functions that given a location name, do the following:\n",
    "\n",
    "* Returns the weather at that location\n",
    "* Returns the date and time at the location\n",
    "\n",
    "Let’s use these functions to create a prompt that asks OpenAI to create a poem about the current weather at that location, taking into account the current time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97b873e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_poem_prompt(location_name):\n",
    "    weather = get_current_weather(location_name)\n",
    "    prompt = (\n",
    "        f\"The weather in {location_name} is {weather['weather']}, \" +\n",
    "        f\"with a temperature of {weather['temperature']} degrees F, \" +\n",
    "        f\"{weather['cloud_cover']}% cloud cover, and \" +\n",
    "        f\"{weather['humidity']}% humidity. \" +\n",
    "        f\"The current date and time there is {get_current_date_and_time_in_location(location_name)}. \" +\n",
    "        \"Create a poem about all this. The poem should also suggest what one should wear \" +\n",
    "        \"for this weather, and whether they should wear a sweater.\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba5b6f",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5f5fb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The weather in Dubai is partly cloudy, with a temperature of 93.02 degrees F, 88% cloud cover, and 79% humidity. The current date and time there is 1:52 AM on Saturday, August 3. Create a poem about all this. The poem should also suggest what one should wear for this weather, and whether they should wear a sweater.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_weather_poem_prompt(\"Dubai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35774923",
   "metadata": {},
   "source": [
    "We now need a function that given a location name, creates a poem about the weather there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cac922a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_poem_for_location(location):\n",
    "    return create_completion(create_weather_poem_prompt(location))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991bac5c",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a156043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Dubai’s embrace, the night softly gleams,  \n",
      "Partly cloudy skies weave a tapestry of dreams.  \n",
      "At one fifty-two, on an August night,  \n",
      "The temperature whispers, “Feel my warm light.”  \n",
      "\n",
      "Ninety-three degrees, a sultry delight,  \n",
      "With clouds lightly dancing, a mesmerizing sight.  \n",
      "Eighty-eight percent of the heavens concealed,  \n",
      "While the air, thick with warmth, gently feels revealed.  \n",
      "\n",
      "Humidity clings like a lover's soft sigh,  \n",
      "At seventy-nine percent, it wraps you nearby.  \n",
      "So step out in comfort, let fashion be free,  \n",
      "Choose light, breathable fabrics, for that’s the key.  \n",
      "\n",
      "A cotton T-shirt, perhaps linen attire,  \n",
      "Shorts or a skirt, to let breezes inspire.  \n",
      "Leave sweaters behind, for warmth is your friend,  \n",
      "In this desert city, where the heat will not end.  \n",
      "\n",
      "So stroll through the night, let the stars be your guide,  \n",
      "With a smile on your face and the world at your side.  \n",
      "In Dubai’s warm embrace, let the evening unfold,  \n",
      "Wrapped in the warmth of a night that’s pure gold.\n"
     ]
    }
   ],
   "source": [
    "print(create_weather_poem_for_location(\"Dubai\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee00f9-fa14-41d0-ac5e-22d9d20ea140",
   "metadata": {},
   "source": [
    "## Integrating ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06c099b4-a25d-4ff1-9ae3-f249e510e296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elevenlabs\n",
      "  Downloading elevenlabs-1.6.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elevenlabs) (0.27.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elevenlabs) (2.8.2)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elevenlabs) (2.20.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elevenlabs) (2.32.3)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from elevenlabs) (4.12.2)\n",
      "Collecting websockets>=11.0 (from elevenlabs)\n",
      "  Using cached websockets-12.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.21.2->elevenlabs) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.21.2->elevenlabs) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.21.2->elevenlabs) (1.0.5)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.21.2->elevenlabs) (3.7)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx>=0.21.2->elevenlabs) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.21.2->elevenlabs) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=1.9.2->elevenlabs) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.20->elevenlabs) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.20->elevenlabs) (2.2.2)\n",
      "Downloading elevenlabs-1.6.1-py3-none-any.whl (129 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached websockets-12.0-cp312-cp312-macosx_11_0_arm64.whl (121 kB)\n",
      "Installing collected packages: websockets, elevenlabs\n",
      "Successfully installed elevenlabs-1.6.1 websockets-12.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08d5f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "load_dotenv()\n",
    "elevenlabs_client = ElevenLabs()\n",
    "\n",
    "# brew install ffmpeg\n",
    "# https://ffmpeg.org/\n",
    "\n",
    "def recite_weather_poem(location):\n",
    "    audio = elevenlabs_client.generate(\n",
    "        text = create_weather_poem_for_location(location),\n",
    "    )\n",
    "    elevenlabs.play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "712f5f70-4504-41e5-9071-28baebc5fc8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiError",
     "evalue": "status_code: 400, body: {'detail': {'status': 'max_character_limit_exceeded', 'message': \"This request's text has 897.0 characters and exceeds the character limit of 500 characters for non signed in accounts.\"}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrecite_weather_poem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTampa, FL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 13\u001b[0m, in \u001b[0;36mrecite_weather_poem\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecite_weather_poem\u001b[39m(location):\n\u001b[1;32m     10\u001b[0m     audio \u001b[38;5;241m=\u001b[39m elevenlabs_client\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     11\u001b[0m         text \u001b[38;5;241m=\u001b[39m create_weather_poem_for_location(location),\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0m     \u001b[43melevenlabs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/elevenlabs/play.py:19\u001b[0m, in \u001b[0;36mplay\u001b[0;34m(audio, notebook, use_ffmpeg)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay\u001b[39m(\n\u001b[1;32m     14\u001b[0m     audio: Union[\u001b[38;5;28mbytes\u001b[39m, Iterator[\u001b[38;5;28mbytes\u001b[39m]], \n\u001b[1;32m     15\u001b[0m     notebook: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     16\u001b[0m     use_ffmpeg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, Iterator):\n\u001b[0;32m---> 19\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m notebook:\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/elevenlabs/text_to_speech/client.py:158\u001b[0m, in \u001b[0;36mTextToSpeechClient.convert\u001b[0;34m(self, voice_id, text, enable_logging, optimize_streaming_latency, output_format, model_id, language_code, voice_settings, pronunciation_dictionary_locators, seed, previous_text, next_text, previous_request_ids, next_request_ids, request_options)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response_json)\n",
      "\u001b[0;31mApiError\u001b[0m: status_code: 400, body: {'detail': {'status': 'max_character_limit_exceeded', 'message': \"This request's text has 897.0 characters and exceeds the character limit of 500 characters for non signed in accounts.\"}}"
     ]
    }
   ],
   "source": [
    "recite_weather_poem(\"Tampa, FL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c239ce",
   "metadata": {},
   "source": [
    "## Integrating DALL-E\n",
    "\n",
    "Given a prompt and a couple of additional parameters, OpenAI’s `client.images.generate()` method returns an image based on that prompt.\n",
    "\n",
    "Here’s a function that creates an image based on a given prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9149490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dall_e_image(description):\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=description,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "    return response.data[0].url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7b204",
   "metadata": {},
   "source": [
    "Here’s a description of `Image.create()`’s parameters:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><strong>Parameter</strong></td>\n",
    "        <td style=\"text-align:left;\"><strong>Description</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>prompt</code></td>\n",
    "        <td style=\"text-align:left;\">A description of the image that OpenAI should generate.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>n</code></td>\n",
    "        <td>The number of images that OpenAI should generate. This should be a value between 1 and 10 inclusive.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>size</code></td>\n",
    "        <td style=\"text-align:left;\">The dimensions of the image. This can be one of the following string values:\n",
    "            <ul>\n",
    "                <li><code>1024x1024</code></li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb9250",
   "metadata": {},
   "source": [
    "Let’s test the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18927530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-9tpXel0y9Ruoie3h4bgEBg89/user-TjzZYjpdoc6SBcrzMSmX08vX/img-DJMMartPOgEeIU2miEDJOEhe.png?st=2024-07-08T18%3A39%3A12Z&se=2024-07-08T20%3A39%3A12Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-08T18%3A14%3A28Z&ske=2024-07-09T18%3A14%3A28Z&sks=b&skv=2023-11-03&sig=zMpsGi3uv47RqvSzQCyLhqD1lG85636fOqLTa3Ir7w4%3D'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dall_e_image(\"A pug dressed up as a witch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34a73a",
   "metadata": {},
   "source": [
    "Note that it returns a URL. Image URLs expire in an hour.\n",
    "\n",
    "Let’s write a function to create a weather image using the functions we’ve already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfad19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_image(location_name):\n",
    "    weather = get_current_weather(location_name)\n",
    "    prompt = (\n",
    "        f\"The skyline view of {location_name}, where the weather is {weather['weather']}, \" +\n",
    "        f\"and the cloud cover is {weather['cloud_cover']}%. \" +\n",
    "        \"Include people dressed appropriately for the weather.\"\n",
    "    )\n",
    "    weather_image_url = create_dall_e_image(create_weather_poem_for_location(location_name))\n",
    "    return weather_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c2392",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "466b18d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://oaidalleapiprodscus.blob.core.windows.net/private/org-9tpXel0y9Ruoie3h4bgEBg89/user-TjzZYjpdoc6SBcrzMSmX08vX/img-MNiOLFS9Jso95zmSsbqTFYav.png?st=2024-07-08T18%3A40%3A02Z&se=2024-07-08T20%3A40%3A02Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-07-08T18%3A32%3A34Z&ske=2024-07-09T18%3A32%3A34Z&sks=b&skv=2023-11-03&sig=C2iKa/5mh/5JI%2B2GKN%2B8sJ581D07de/9eO2tlcAqyGI%3D'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_weather_image(\"Austin, TX\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
