{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35754509",
   "metadata": {},
   "source": [
    "# Lesson 5 project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d5ac4",
   "metadata": {},
   "source": [
    "## Install the OpenAI Python package on your system\n",
    "\n",
    "Like any other Python package, you install the OpenAI package using `pip`, which is short for “Package Installer for Python.” Run the cell below to install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c70c1",
   "metadata": {},
   "source": [
    "(If the above doesn’t work, try `pip3 install openai` instead.)\n",
    "\n",
    "In a Jupyter Notebook code cell, any line that begins with the `!` character is executed as a shell command — that is, it’s as if you typed it on the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e4347",
   "metadata": {},
   "source": [
    "## Create an OpenAI client object\n",
    "\n",
    "To make use of OpenAI’s APIs, you need to create an OpenAI ___client___ object. You’ll use it throughout the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d709a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# When called without arguments, OpenAI will try to get\n",
    "# the API key from the OPENAI_API_KEY environment variable.\n",
    "load_dotenv()\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2af18",
   "metadata": {},
   "source": [
    "\n",
    "In the ChatGPT API, a ___completion___ refers to the response generated by the model based on the input it receives. When you send a prompt to the API, the model processes this input and produces a text output, which is the \"completion.\" This output is intended to complete the prompt in a coherent and contextually relevant manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac423b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_model = \"gpt-4o-mini\"\n",
    "prompt = input(f\"Ask OpenAI's {current_model} model a question: \")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=current_model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ede70",
   "metadata": {},
   "source": [
    "The `input()` function collects keyboard input from the user. It takes one argument, which it uses as a prompt (in this case, it’s `Say something: `), and it returns a string containing whatever the user entered. The code above stores whatever the user entered into a variable named prompt.\n",
    "\n",
    "The next line communicates with OpenAI using the `client.chat.completions.create()` method of the `ChatCompletion` class of the `openai` module. The `client.chat.completions.create()` method creates a _ChatCompletion_, which is an artificial intelligence model that takes a number of messages as input and generates a result as output. It’s called a “completion” because you feed it the first part of a conversation, and the result it provides completes the conversation.\n",
    "\n",
    "The code above provides the two parameters that all calls to the `client.chat.completions.create()` method must provide:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><strong>Parameter</strong></td>\n",
    "        <td style=\"text-align:left;\"><strong>Description</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>model</code></td>\n",
    "        <td>\n",
    "            <p>The name of the AI model that should be used to create the completion.</p>\n",
    "            <p>In the code above and in all the code in this exercise, we’re using the _GPT-4o mini_ model, \n",
    "               a “lite” version of their flagship GPT-4o model. It’s useful enough for most purposes, and is \n",
    "               quite inexpensive — generally a fraction of a cent for each completion.</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>messages</code></td>\n",
    "        <td style=\"text-align:left;\">\n",
    "            <p>A list of input messages to be provided to the completion.</p>\n",
    "            <p>Each message is a dictionary containing the following keys:</p>\n",
    "            <ul>\n",
    "                <li>\n",
    "                    <code>“role”</code>: This specifies who the message is from. The message can be from one of three entities:\n",
    "                    <ol>\n",
    "                        <li><code>“user”</code>: Messages with the “user” role contain questions or requests from the user or entity that wants a response from the AI model.</li>\n",
    "                        <li><code>“system”</code>: Messages with the “system” role usually contain some high-level instructions to guide the behavior of the AI. By default, the AI acts as if it was given a “system” message of “You are a helpful assistant.”</li>\n",
    "                        <li><code>“assistant”</code>: This role represents the responses given by the AI model.</li>\n",
    "                    </ol>\n",
    "                </li>\n",
    "                <br />\n",
    "                <li><code>“content”</code>: As its name implies, this contains the content of the message.</li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "The code in the cell provides only one message, where the role is “user” and the message is the contents of the prompt variable, which contains whatever the user entered into the text input field.\n",
    "The thing in the `ChatCompletion` object that we’re most interested in is the actual response or response_s_, which are contained in `ChatCompletion`’s `choices` property, which is an array.\n",
    "\n",
    "Each element of `choices` has a `message` property, which represents a message from the model. The text of the message is contained in `message`’s `content` property.\n",
    "\n",
    "Let’s extract the actual message content!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad136743",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716df1f",
   "metadata": {},
   "source": [
    "## Create a chat completion function\n",
    "\n",
    "Let’s take the code we’ve written so far and turn it into a function that takes a prompt as its input and outputs a completion as its result. It will simply be some of the code you’ve written so far, but put inside a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876941d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_completion(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e697f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_completion(\"How much does the Earth weigh?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a91951",
   "metadata": {},
   "source": [
    "## Turn up the temperature on the chat completion function\n",
    "\n",
    "OpenAI’s chat completions have useful optional parameters. One of them is `temperature`, which specifies the amount of randomness in the answers it generates. \n",
    "\n",
    "Temperature is a value typically between 0 and 1, where lower values are supposed to produce completions that are more focused and deterministic, while higher values are expected to be more random and creative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf363f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_completion(prompt, temp=0.7):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a75cd",
   "metadata": {},
   "source": [
    "This redefines the `create_completion()` function and adds a new parameter, `temp`.\n",
    "\n",
    "I’m using Python’s “default argument” feature — if you don’t assign a value to `temp`, it sets it the default value of `0.7`. That should make the completions fairly creative, but not too wild.\n",
    "\n",
    "Try the following. There’s no value for the `temp` parameter, so `create_completion()` will use the default value of `0.7`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10accf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_completion(\"I need two one-paragraph descriptions of characters for a young adult adventure novel set in the age of pirates\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219239e",
   "metadata": {},
   "source": [
    "It turns out that OpenAI’s `temperature` parameter accepts values higher than 1 — they can go as high as 2. The results take a longer time to produce, and they get sillier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1687a003",
   "metadata": {},
   "source": [
    "## Add system guidance to the chat completion function\n",
    "\n",
    "Your application can add additional guidance for OpenAI’s completion by adding a message with a “system” role. Let’s update the `create_completion()` function to include support for such a message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcff064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_completion(prompt, temp=0.7, system_prompt=\"\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=temp,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b1584a",
   "metadata": {},
   "source": [
    "This provides an additional message to OpenAI. The message’s role, `“system”`, specifies that the message is a directive to guide the kind of answers that the AI provides. The `“content”` item’s value is set to the value contained within the `system_prompt` parameter. If you don’t provide a value for `system_prompt`, this value is an empty string, which is the same as not providing any kind of system guidance at all.\n",
    "\n",
    "Let’s test this new `create_completion()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcac16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_completion(\"Explain the first law of thermodynamics\", system_prompt=\"Answer as if you were a shady used car dealer.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf0c5b",
   "metadata": {},
   "source": [
    "## Getting information from other APIs\n",
    "\n",
    "Suppose we want to create an app that gets the weather for a given city and writes a poem about it. We can do that by combining OpenAI and other APIs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e49152",
   "metadata": {},
   "source": [
    "### Get a location’s latitude and longitude from a place name or address\n",
    "\n",
    "The location APIs we’ll be using in this app will require the latitude and longitude of the place in question, so we need to create a function to convert place names to coordinates. We can do this by using a geocoding API. \n",
    "\n",
    "_Geocoding_ is the process of converting a place name or address into coordinates — more specifically latitude and longitude. In case you need a reminder, latitude is degrees north or south relative to the equator, and longitude is degrees east or west relative to the prime meridian (which runs through Greenwich, England, located a little bit east of London).\n",
    "\n",
    "![Chart explaining latitude (horizontal lines parallel to the equator) and longitude (vertical lines parallel to the prime meridian)](https://www.globalnerdy.com/wp-content/uploads/2023/10/latitude-vs-longitude.jpg)\n",
    "\n",
    "[GeoPy](https://geopy.readthedocs.io/en/stable/) is a Python module that makes it easy for a Python application to access several geocoding services, some of which are free, while others require money. We’ll use it to access the [Nominatim](https://nominatim.org/) geocoder, which uses [OpenStreetMap](https://www.openstreetmap.org/) data and doesn’t require you to sign up for an API key or provide a credit card number.\n",
    "\n",
    "First, you’ll need to install GeoPy on your system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94191119",
   "metadata": {},
   "source": [
    "Here’s a function that takes a place name or address and uses Nominatim to convert it into latitude and longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def location_name_to_latlong(location_name):\n",
    "    geolocator = Nominatim(user_agent=\"Computer Coach online AI bootcamp\")\n",
    "    location = geolocator.geocode(location_name)\n",
    "    return (location.latitude, location.longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11365b",
   "metadata": {},
   "source": [
    "The `user_agent` parameter should contain the name of the app using the Nominatim service.\n",
    "\n",
    "Try it out by using it to get the latitude and longitude of Tampa International Airport:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d2e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are Tampa International Airport’s coordinates?\n",
    "location_name_to_latlong(\"Tampa International Airport\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06047b8a",
   "metadata": {},
   "source": [
    "### Get the time at the location\n",
    "\n",
    "The app draws a picture of the location, so it would be helpful if we could provide it with the current time at the location so that it “knows” whether to draw a daytime scene, a nighttime scene, or something in between.\n",
    "\n",
    "To do this, we’ll use the `timezonefinder` package, which takes a latitude/longitude coordinate pair and returns the time zone for those coordinates. It does its job entirely offline; it doesn’t make any calls to external APIs.\n",
    "\n",
    "First, install the `timezonefinder` package..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install timezonefinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34898c92",
   "metadata": {},
   "source": [
    "...and here’s a function that converts coordinates to a time zone name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timezonefinder import TimezoneFinder\n",
    "\n",
    "def get_timezone_from_latlong(latitude_longitude_tuple):\n",
    "    latitude, longitude = latitude_longitude_tuple\n",
    "    tz_finder = TimezoneFinder()\n",
    "    return tz_finder.timezone_at(lat=latitude, lng=longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8decf3ac",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_timezone_from_latlong(location_name_to_latlong(\"Tampa, FL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b266578",
   "metadata": {},
   "source": [
    "Now that we know the time zone for the location, we need the time at that location. There are a number of ways to do this; I’ve chosen to use the [World Time API](https://worldtimeapi.org/).\n",
    "\n",
    "Here’s a function that takes a timezone name and returns the current date and time in that time zone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9da8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def get_current_date_and_time_in_timezone(timezone_name):\n",
    "    url = f\"http://worldtimeapi.org/api/timezone/{timezone_name}\"\n",
    "    response = requests.get(url)\n",
    "    json = response.json()\n",
    "    raw_date_and_time = json[\"datetime\"]\n",
    "    date_and_time = datetime.strptime(raw_date_and_time, \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    current_time = datetime.strftime(date_and_time, \"%-I:%M %p on %A, %B %-d\")\n",
    "    return current_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a9850",
   "metadata": {},
   "source": [
    "Once we have that function, we can write a function that takes a location name and returns the current date and time at that location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f79b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_date_and_time_in_location(location_name):\n",
    "    return get_current_date_and_time_in_timezone(\n",
    "        get_timezone_from_latlong(location_name_to_latlong(location_name))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e10f05",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_date_and_time_in_location(\"San Francisco, CA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a87b1",
   "metadata": {},
   "source": [
    "### Get the current weather\n",
    "\n",
    "There are a number of weather APIs out there. Let’s use the one from [Open-Meteo](https://open-meteo.com/) — _météo_ is French for _weather_ — which is free for non-commercial use and if you make fewer than 10,000 calls to it per day. It’s perfect for experimental applications or apps with relatively few users. It doesn’t require you to sign up for an API key, and you don’t have to provide a credit card number. You can just use it.\n",
    "\n",
    "You can find out more about the API in [Open-Meteo’s documentation](https://open-meteo.com/en/docs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a20424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# import json\n",
    "\n",
    "WEATHER_CODE_TABLE = {\n",
    "    0: \"clear sky\",\n",
    "    1: \"mainly clear\",\n",
    "    2: \"partly cloudy\",\n",
    "    3: \"overcast\",\n",
    "    45: \"fog\",\n",
    "    48: \"depositing rime fog\",\n",
    "    51: \"light drizzle\",\n",
    "    53: \"moderate drizzle\",\n",
    "    55: \"dense drizzle\",\n",
    "    56: \"light freezing drizzle\",\n",
    "    57: \"dense freezing drizzle\",\n",
    "    61: \"slight rain\",\n",
    "    63: \"moderate rain\",\n",
    "    65: \"heavy rain\",\n",
    "    66: \"light freezing rain\",\n",
    "    67: \"heavy freezing rain\",\n",
    "    71: \"slight snow\",\n",
    "    73: \"moderate snow\",\n",
    "    75: \"heavy snow\",\n",
    "    77: \"snow grains\",\n",
    "    80: \"light rain showers\",\n",
    "    81: \"moderate rain showers\",\n",
    "    82: \"violent rain showers\",\n",
    "    85: \"slight snow showers\",\n",
    "    86: \"heavy snow showers\",\n",
    "    95: \"thunderstorm\",\n",
    "    96: \"thunderstorm with slight hail\",\n",
    "    99: \"thunderstorm with heavy hail\",\n",
    "}\n",
    "\n",
    "def celsius_to_fahrenheit(degrees_celsius):\n",
    "    return (degrees_celsius * 1.8) + 32\n",
    "\n",
    "def get_current_weather(location_name):\n",
    "    latitude, longitude = location_name_to_latlong(location_name)\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,relativehumidity_2m,weathercode,cloudcover\"\n",
    "    response = requests.get(url)\n",
    "    json = response.json()\n",
    "    result = {\n",
    "        \"weather\": WEATHER_CODE_TABLE.get(json[\"current\"][\"weathercode\"], \"unknown\"),\n",
    "        \"cloud_cover\": json[\"current\"][\"cloudcover\"],\n",
    "        \"temperature\": celsius_to_fahrenheit(json[\"current\"][\"temperature_2m\"]),\n",
    "        \"humidity\": json[\"current\"][\"relativehumidity_2m\"],\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76717b5",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "Here’s what the `import`ed modules do:\n",
    "    \n",
    "* **`requests`**: Contains functions for sending HTTP requests.\n",
    "* **`json`**: Contains functions for encoding and decoding JSON data.\n",
    "\n",
    "The next part of the code defines a dictionary called `WMO_CODE_TABLE`,  which is used to convert Open-Meteo’s weather forecast numbers into meaningful phrases, such as converting “2” into something more comprehensible: “partly cloudy.”\n",
    "\n",
    "The final part of the code is the function itself — `get_current_weather()` — which takes a place name or address and returns a dictionary containing key elements of the forecast:\n",
    "\n",
    "* The weather, expressed as a weather code number\n",
    "* Cloud cover, expressed as a percentage\n",
    "* Temperature, in degrees C\n",
    "* Humidity, expressed as a percentage\n",
    "\n",
    "Open-Meteo’s API expects latitude and longitude, not a place name. That’s where the `location_name_to_latlong()` function we wrote earlier comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60520e0a",
   "metadata": {},
   "source": [
    "Try out the `get_current_weather()` function for Tampa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5462e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_weather(\"Tampa, FL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be4a50c",
   "metadata": {},
   "source": [
    "### Create a weather poem prompt\n",
    "\n",
    "We now have functions that given a location name, do the following:\n",
    "\n",
    "* Returns the weather at that location\n",
    "* Returns the date and time at the location\n",
    "\n",
    "Let’s use these functions to create a prompt that asks OpenAI to create a poem about the current weather at that location, taking into account the current time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b873e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_poem_prompt(location_name):\n",
    "    weather = get_current_weather(location_name)\n",
    "    prompt = (\n",
    "        f\"The weather in {location_name} is {weather['weather']}, \" +\n",
    "        f\"with a temperature of {weather['temperature']} degrees F, \" +\n",
    "        f\"{weather['cloud_cover']}% cloud cover, and \" +\n",
    "        f\"{weather['humidity']}% humidity. \" +\n",
    "        f\"The current date and time there is {get_current_date_and_time_in_location(location_name)}. \" +\n",
    "        \"Create a poem about all this. The poem should also suggest what one should wear \" +\n",
    "        \"for this weather, and whether they should wear a sweater.\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba5b6f",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_weather_poem_prompt(\"Dubai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35774923",
   "metadata": {},
   "source": [
    "We now need a function that given a location name, creates a poem about the weather there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac922a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_poem_for_location(location):\n",
    "    return create_completion(create_weather_poem_prompt(location))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991bac5c",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a156043",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(create_weather_poem_for_location(\"Dubai\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee00f9-fa14-41d0-ac5e-22d9d20ea140",
   "metadata": {},
   "source": [
    "## Integrating ElevenLabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c099b4-a25d-4ff1-9ae3-f249e510e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "load_dotenv()\n",
    "elevenlabs_client = ElevenLabs()\n",
    "\n",
    "# brew install ffmpeg\n",
    "# https://ffmpeg.org/\n",
    "\n",
    "def recite_weather_poem(location):\n",
    "    audio = elevenlabs_client.generate(\n",
    "        text = create_weather_poem_for_location(location),\n",
    "    )\n",
    "    elevenlabs.play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f5f70-4504-41e5-9071-28baebc5fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recite_weather_poem(\"Tampa, FL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c239ce",
   "metadata": {},
   "source": [
    "## Integrating DALL-E\n",
    "\n",
    "Given a prompt and a couple of additional parameters, OpenAI’s `client.images.generate()` method returns an image based on that prompt.\n",
    "\n",
    "Here’s a function that creates an image based on a given prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9149490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dall_e_image(description):\n",
    "    response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt=description,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "    return response.data[0].url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7b204",
   "metadata": {},
   "source": [
    "Here’s a description of `Image.create()`’s parameters:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><strong>Parameter</strong></td>\n",
    "        <td style=\"text-align:left;\"><strong>Description</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>prompt</code></td>\n",
    "        <td style=\"text-align:left;\">A description of the image that OpenAI should generate.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>n</code></td>\n",
    "        <td>The number of images that OpenAI should generate. This should be a value between 1 and 10 inclusive.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><code>size</code></td>\n",
    "        <td style=\"text-align:left;\">The dimensions of the image. This can be one of the following string values:\n",
    "            <ul>\n",
    "                <li><code>1024x1024</code></li>\n",
    "            </ul>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb9250",
   "metadata": {},
   "source": [
    "Let’s test the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18927530",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dall_e_image(\"A pug dressed up as a witch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34a73a",
   "metadata": {},
   "source": [
    "Note that it returns a URL. Image URLs expire in an hour.\n",
    "\n",
    "Let’s write a function to create a weather image using the functions we’ve already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfad19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weather_image(location_name):\n",
    "    weather = get_current_weather(location_name)\n",
    "    prompt = (\n",
    "        f\"The skyline view of {location_name}, where the weather is {weather['weather']}, \" +\n",
    "        f\"and the cloud cover is {weather['cloud_cover']}%. \" +\n",
    "        \"Include people dressed appropriately for the weather.\"\n",
    "    )\n",
    "    weather_image_url = create_dall_e_image(create_weather_poem_for_location(location_name))\n",
    "    return weather_image_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c2392",
   "metadata": {},
   "source": [
    "Let’s test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_weather_image(\"Austin, TX\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
